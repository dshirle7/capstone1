{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'id', 'date_account_created', 'timestamp_first_active',\n",
      "       'date_first_booking', 'gender', 'age', 'signup_method', 'signup_flow',\n",
      "       'language', 'affiliate_channel', 'affiliate_provider',\n",
      "       'first_affiliate_tracked', 'signup_app', 'first_device_type',\n",
      "       'first_browser', 'country_destination', 'days_thinking',\n",
      "       'number_of_actions'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# The purpose of this notebook is to compare the\n",
    "# efficacy of various Machine Learning models on\n",
    "# the dataset.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "script_dir = os.path.abspath('')\n",
    "\n",
    "file = os.path.realpath(script_dir + '/../data/interim/train_users_2_2.csv')\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset for our regression\n",
    "\n",
    "df2 = 0\n",
    "\n",
    "# Remove undesired columns\n",
    "\n",
    "# Note we do NOT want date_first_booking in\n",
    "# our model because it is not included in\n",
    "# the test set of the competition.\n",
    "\n",
    "df2 = df[['date_account_created',\n",
    "          'gender',\n",
    "          'age',\n",
    "          'signup_method',\n",
    "          'language',\n",
    "          'affiliate_channel',\n",
    "          'affiliate_provider',\n",
    "          'first_affiliate_tracked',\n",
    "          'signup_app',\n",
    "          'first_device_type',\n",
    "          'first_browser',\n",
    "          'number_of_actions',\n",
    "          'country_destination']]\n",
    "\n",
    "# Convert time-based columns to datetime\n",
    "# objects, then to numbers that the model\n",
    "# can use.\n",
    "\n",
    "df2['week_account_created'] = pd.to_datetime(df2['date_account_created']).dt.week\n",
    "\n",
    "df2 = df2.drop(['date_account_created'], axis=1)\n",
    "\n",
    "df2.fillna(0, inplace=True)\n",
    "\n",
    "# Use get_dummies to convert our categorical\n",
    "# features to numerical features so that our\n",
    "# model can use them.\n",
    "\n",
    "dummiescols = ['gender', 'signup_method', 'language',\n",
    "               'affiliate_channel', 'affiliate_provider',\n",
    "               'first_affiliate_tracked', 'signup_app',\n",
    "               'first_device_type', 'first_browser']\n",
    "\n",
    "df2 = pd.get_dummies(df2, prefix=dummiescols, columns=dummiescols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df2.drop('country_destination', axis=1).values,\n",
    "    df2['country_destination'].values,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5180819409475853"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Train the model, then score it on the test set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NDF', 'NL', 'PT', 'US', 'other']\n",
      "[[   0    0    0    0    0    0    0   16    0    0   16    0]\n",
      " [   0    0    0    0    0    0    0   19    0    0   50    0]\n",
      " [   0    0    0    0    0    0    0   20    0    0   28    0]\n",
      " [   0    0    0    0    0    0    0   39    0    0   78    0]\n",
      " [   0    0    0    0    0    0    0   75    0    0  166    0]\n",
      " [   0    0    0    0    0    0    0   43    0    0  106    0]\n",
      " [   0    0    0    0    0    0    0   58    0    0  101    0]\n",
      " [   0    0    0    0    0    0    0 2166    0    0 1578    0]\n",
      " [   0    0    0    0    0    0    0   18    0    0   25    0]\n",
      " [   0    0    0    0    0    0    0    2    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0 1185    0    0 2361    0]\n",
      " [   0    0    0    0    0    0    0  196    0    0  382    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ylr_pred = logreg.predict(X_test)\n",
    "\n",
    "labels = [i for i in unique_labels(y_test, ylr_pred)]\n",
    "\n",
    "print(labels)\n",
    "\n",
    "cm = confusion_matrix(y_test, ylr_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47894254978255896"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NDF', 'NL', 'PT', 'US', 'other']\n",
      "[[   0    0    0    0    0    0    0   18    0    0   14    0]\n",
      " [   0    1    0    0    0    0    0   28    0    0   39    1]\n",
      " [   0    0    0    0    0    0    0   25    0    0   21    2]\n",
      " [   1    1    0    0    1    0    0   54    0    0   57    3]\n",
      " [   0    0    0    0    2    2    0  110    0    0  121    6]\n",
      " [   0    0    0    0    0    0    1   62    0    0   86    0]\n",
      " [   0    0    0    1    3    0    0   75    0    0   77    3]\n",
      " [   1    1    2    9   21    8    4 2202    0    0 1460   36]\n",
      " [   0    0    0    0    0    0    0   21    0    0   21    1]\n",
      " [   0    0    0    0    0    0    0    4    0    0    8    0]\n",
      " [   1    5    2   13   16    6   15 1458    3    0 1968   59]\n",
      " [   0    1    0    0    3    0    2  254    0    0  306   12]]\n"
     ]
    }
   ],
   "source": [
    "yrf_pred = rf.predict(X_test)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, yrf_pred)\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5203707942320898"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "ab.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NDF', 'NL', 'PT', 'US', 'other']\n",
      "[[   0    0    0    0    0    0    0   15    0    0   17    0]\n",
      " [   0    0    0    0    0    0    0   20    0    0   49    0]\n",
      " [   0    0    0    0    0    0    0   20    0    0   28    0]\n",
      " [   0    0    0    0    0    0    0   42    0    0   75    0]\n",
      " [   0    0    0    0    0    0    0   83    0    0  158    0]\n",
      " [   0    0    0    0    0    0    0   48    0    1  100    0]\n",
      " [   0    0    0    0    0    0    0   61    0    0   98    0]\n",
      " [   0    0    0    0    0    0    0 2232    0    4 1508    0]\n",
      " [   0    0    0    0    0    0    0   19    0    0   24    0]\n",
      " [   0    0    0    0    0    0    0    4    0    0    8    0]\n",
      " [   0    0    0    0    0    0    0 1230    0    1 2315    0]\n",
      " [   0    0    0    0    0    0    0  210    0    0  368    0]]\n"
     ]
    }
   ],
   "source": [
    "yab_pred = ab.predict(X_test)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "cm3 = confusion_matrix(y_test, yab_pred)\n",
    "\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other' 'US' 'FR' 'GB' 'IT' 'AU' 'CA' 'ES' 'DE' 'NL' 'PT']\n"
     ]
    }
   ],
   "source": [
    "# Looks like our algorithms are only ever\n",
    "# predicting NDF or US as the classifier.\n",
    "# I wonder if we can get a better result\n",
    "# by removing NDF entirely. If so, we can\n",
    "# just create a separate algorithm to sort\n",
    "# the data into \"NDF\" or \"Made a Booking\".\n",
    "\n",
    "df3 = df2[df2['country_destination'] != 'NDF']\n",
    "\n",
    "print(df3['country_destination'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
    "    df3.drop('country_destination', axis=1).values,\n",
    "    df3['country_destination'].values,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7182475884244373"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg3 = LogisticRegression()\n",
    "\n",
    "logreg3.fit(X3_train, y3_train)\n",
    "\n",
    "logreg3.score(X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NL', 'PT', 'US', 'other']\n",
      "[[   0    0    0    0    0    0    0    0    0   33    0]\n",
      " [   0    0    0    0    0    0    0    0    0   85    0]\n",
      " [   0    0    0    0    0    0    0    0    0   40    0]\n",
      " [   0    0    0    0    0    0    0    0    0  107    0]\n",
      " [   0    0    0    0    0    0    0    0    0  238    0]\n",
      " [   0    0    0    0    0    0    0    0    0  119    0]\n",
      " [   0    0    0    0    0    0    0    0    0  144    0]\n",
      " [   0    0    0    0    0    0    0    0    0   43    0]\n",
      " [   0    0    0    0    0    0    0    0    0    8    0]\n",
      " [   0    0    0    0    0    0    0    0    0 3574    0]\n",
      " [   0    0    0    0    0    0    0    0    0  585    0]]\n"
     ]
    }
   ],
   "source": [
    "ylr3_pred = logreg3.predict(X3_test)\n",
    "\n",
    "labels3 = [i for i in unique_labels(y3_test, ylr3_pred)]\n",
    "\n",
    "print(labels3)\n",
    "\n",
    "cm = confusion_matrix(y3_test, ylr3_pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Nope. It's still just saying everyone travels to the US.\n",
    "# Let's try one more time, eliminating the US as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other' 'FR' 'GB' 'IT' 'AU' 'CA' 'ES' 'DE' 'NL' 'PT']\n"
     ]
    }
   ],
   "source": [
    "df4 = df3[df3['country_destination'] != 'US']\n",
    "\n",
    "print(df4['country_destination'].unique())\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(\n",
    "    df4.drop('country_destination', axis=1).values,\n",
    "    df4['country_destination'].values,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4271639690358902"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg4 = LogisticRegression()\n",
    "\n",
    "logreg4.fit(X4_train, y4_train)\n",
    "\n",
    "logreg4.score(X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NL', 'PT', 'other']\n",
      "[[  0   0   0   0   0   0   0   0   0  30]\n",
      " [  0   0   0   0   1   0   0   0   0  90]\n",
      " [  0   0   0   0   1   0   1   0   0  43]\n",
      " [  0   0   1   0   5   0   0   0   0 106]\n",
      " [  0   0   1   0   7   0   1   0   0 232]\n",
      " [  0   0   0   0   2   0   0   0   0  98]\n",
      " [  0   0   1   0   4   0   1   0   0 133]\n",
      " [  0   0   0   0   0   0   0   0   0  40]\n",
      " [  0   0   0   0   0   0   0   0   0  10]\n",
      " [  0   0   1   2   9   0   2   0   0 599]]\n"
     ]
    }
   ],
   "source": [
    "ylr4_pred = logreg4.predict(X4_test)\n",
    "\n",
    "labels4 = [i for i in unique_labels(y4_test, ylr4_pred)]\n",
    "\n",
    "print(labels4)\n",
    "\n",
    "cm = confusion_matrix(y4_test, ylr4_pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Our model is pretty weak. It looks like it just\n",
    "# assigns the data to the most popular destination in\n",
    "# the dataset. Let's remove 'other' and see what\n",
    "# happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FR' 'GB' 'IT' 'AU' 'CA' 'ES' 'DE' 'NL' 'PT']\n"
     ]
    }
   ],
   "source": [
    "df5 = df4[df4['country_destination'] != 'other']\n",
    "\n",
    "print(df5['country_destination'].unique())\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(\n",
    "    df5.drop('country_destination', axis=1).values,\n",
    "    df5['country_destination'].values,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\d\\Anaconda3\\envs\\capstone1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2733812949640288"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg5 = LogisticRegression()\n",
    "\n",
    "logreg5.fit(X5_train, y5_train)\n",
    "\n",
    "logreg5.score(X5_test, y5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NL', 'PT']\n",
      "[[  0   0   0   4  25   1   1   0   0]\n",
      " [  0   1   1   5  68   4   4   0   0]\n",
      " [  0   1   1   1  40   0   3   0   0]\n",
      " [  0   1   1   3  97   1   1   0   0]\n",
      " [  0   1   0  12 215   2   9   0   0]\n",
      " [  0   0   0   2 114   3   4   0   0]\n",
      " [  0   0   1   2 140   3   5   0   0]\n",
      " [  0   0   0   2  38   2   4   0   0]\n",
      " [  0   0   0   0  11   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "ylr5_pred = logreg5.predict(X5_test)\n",
    "\n",
    "labels5 = [i for i in unique_labels(y5_test, ylr5_pred)]\n",
    "\n",
    "print(labels5)\n",
    "\n",
    "cm = confusion_matrix(y5_test, ylr5_pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Ok. It's turtles all the way down. Just\n",
    "# to be sure, try Random Forests and AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22302158273381295"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf5 = RandomForestClassifier(n_estimators=300)\n",
    "\n",
    "rf5.fit(X5_train, y5_train)\n",
    "\n",
    "rf5.score(X5_test, y5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24700239808153476"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab5 = AdaBoostClassifier()\n",
    "\n",
    "ab5.fit(X5_train, y5_train)\n",
    "\n",
    "ab5.score(X5_test, y5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very clear what's going on here: the models have little ability to discern between the less popular destination spots. We were getting such accurate results in the first case solely because two features—NDF and US—absolutely dwarf the other target categories. To proceed, I will need to understand how to predict even despite very unevenly distributed target classes.\n",
    "\n",
    "Perhaps it is time to re-wrangle things and re-introduce users for whom\n",
    "data is missing. It could be that a larger training set would allow for\n",
    "a better result. I think I will also start performing these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jumbled mess; not for public consumption. Keeping for archival purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df_train = pd.read_csv('../../data/processed/train_users_2.csv')\n",
    "df_test = pd.read_csv('../../data/processed/test_users.csv')\n",
    "target = df_train['country_destination'].values\n",
    "df_train = df_train.drop(['id', 'country_destination'], axis=1)\n",
    "id_test = df_test['id']\n",
    "df_test = df_test.drop(['id'], axis=1)\n",
    "\n",
    "df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "df_train = df_train.fillna(-2)\n",
    "df_test = df_test.replace([np.inf, -np.inf], np.nan)\n",
    "df_test = df_test.fillna(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "null_train=df_train.columns[df_train.isnull().any()]\n",
    "print(null_train)\n",
    "\n",
    "null_test=df_train.columns[df_train.isnull().any()]\n",
    "print(null_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00000000e+00  2.01000000e+03  6.00000000e+00 ... -2.00000000e+00\n",
      "  -2.00000000e+00 -2.00000000e+00]\n",
      " [ 3.80000000e+01  2.01100000e+03  5.00000000e+00 ... -2.00000000e+00\n",
      "  -2.00000000e+00 -2.00000000e+00]\n",
      " [ 5.60000000e+01  2.01000000e+03  9.00000000e+00 ... -2.00000000e+00\n",
      "  -2.00000000e+00 -2.00000000e+00]\n",
      " ...\n",
      " [ 3.20000000e+01  2.01400000e+03  6.00000000e+00 ...  3.42982000e+05\n",
      "   2.01754118e+04  4.23254679e+04]\n",
      " [-1.00000000e+00  2.01400000e+03  6.00000000e+00 ...  3.41609000e+05\n",
      "   4.61633784e+03  8.90996884e+03]\n",
      " [-1.00000000e+00  2.01400000e+03  6.00000000e+00 ...  2.75921000e+06\n",
      "   6.89802500e+04  2.73217316e+05]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting train and test\n",
    "X_train = df_train.to_numpy()\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(target)\n",
    "X_test = df_test.to_numpy()\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying SMOTE, then GBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# smote_gb = GradientBoostingClassifier(n_estimators=40, learning_rate=0.2,\n",
    "#                                    max_depth=8, subsample=0.8, random_state=0,\n",
    "#                                    max_features=int(len(df_train.columns) ** 0.5))\n",
    "# parameters = {'n_estimators': [40, 50, 60, 70, 80, 90, 100]}\n",
    "\n",
    "# clfsmote = GridSearchCV(smote_gb, parameters, cv=3)\n",
    "\n",
    "# clfsmote.fit(X_train_res, y_train_res)\n",
    "\n",
    "# JUMP TO BOTTOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 30, 90, 270], 'learning_rate': [0.05, 0.1, 0.2], 'max_depth': [3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "smote_xg = XGBClassifier(random_state=0)\n",
    "\n",
    "parameters = {'n_estimators': [10, 30, 90, 270],\n",
    "              'learning_rate': [0.05, 0.1, 0.2],\n",
    "              'max_depth': [3, 4, 5]}\n",
    "\n",
    "smote_grid = GridSearchCV(smote_xg, parameters, cv=3)\n",
    "\n",
    "smote_grid.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=270,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "0.44787476346857447\n",
      "{'mean_fit_time': array([  789.9915808 ,  2204.14271442,  6406.64405759, 19140.48946905,\n",
      "         921.1424365 ,  2692.819369  ,  7977.4251066 , 23691.78840669,\n",
      "        1097.1732134 ,  3240.16687409,  9589.44090573, 28492.44999647,\n",
      "         743.70760282,  2171.10937905,  6419.67270756, 19143.96723167,\n",
      "         914.7092731 ,  2687.05369337,  7963.60860697, 23680.63061841,\n",
      "        1098.00649762,  3219.8140227 ,  9529.82833624, 28300.13595104,\n",
      "         751.13120023,  2167.07763815,  6388.66619094, 19150.86069942,\n",
      "         919.48051476,  2674.56755058,  7896.6413126 , 23613.06027063,\n",
      "        1101.33287048,  3224.4769671 ,  9468.43024365, 28127.63979761]), 'std_fit_time': array([  7.29727502,  70.92764033,  40.80532494, 154.11773934,\n",
      "         6.73221325,  21.93496024,  63.87630365, 207.6337076 ,\n",
      "         9.6819708 ,  24.3791647 , 102.70966386, 305.23790732,\n",
      "         3.2757654 ,  12.86535011,  48.96465956, 149.20631447,\n",
      "         5.81073691,  19.09830451,  64.56378505, 176.23059906,\n",
      "        10.75140223,  29.06152362, 111.468244  , 275.5862666 ,\n",
      "         3.41710398,  19.09779032,  42.98421624, 112.49929697,\n",
      "        10.44180073,  30.25656487,  72.89021058, 209.71652614,\n",
      "         9.08262872,  38.20172254, 113.62909402, 360.02245512]), 'mean_score_time': array([ 14.55711643,  17.3225944 ,  32.58095551,  70.96012076,\n",
      "        14.62795552,  19.91415215,  38.49576926,  87.10344084,\n",
      "        14.75762383,  22.62983354,  44.82639257, 109.6202596 ,\n",
      "        13.98326786,  18.16829427,  32.10319217,  68.21845039,\n",
      "        14.43641432,  21.03893892,  37.76027958,  83.44313272,\n",
      "        14.96704268,  23.0791177 ,  44.62764549, 103.30885871,\n",
      "        14.15907399,  18.12415767,  31.38018004,  65.00780233,\n",
      "        14.86715484,  20.24644788,  36.87401032,  79.38085604,\n",
      "        15.04266477,  23.10073765,  43.35285751,  99.63592339]), 'std_score_time': array([0.11314619, 0.14984069, 0.29733382, 1.40025999, 0.31603512,\n",
      "       0.34192996, 1.28575918, 2.35875463, 0.07653678, 0.44476935,\n",
      "       0.877906  , 2.11342067, 0.16348137, 0.15790562, 0.71289775,\n",
      "       1.61135819, 0.04464539, 0.20746973, 0.49921901, 2.05166951,\n",
      "       0.09314667, 0.5353966 , 0.63246051, 2.41101354, 0.06555434,\n",
      "       0.19159598, 0.91259964, 1.37985837, 0.34289461, 0.21764142,\n",
      "       0.9731008 , 2.22337328, 0.07183073, 0.48516967, 0.90590158,\n",
      "       4.19012451]), 'param_learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 4, 4,\n",
      "                   4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[10, 30, 90, 270, 10, 30, 90, 270, 10, 30, 90, 270, 10,\n",
      "                   30, 90, 270, 10, 30, 90, 270, 10, 30, 90, 270, 10, 30,\n",
      "                   90, 270, 10, 30, 90, 270, 10, 30, 90, 270],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 10}, {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 30}, {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 90}, {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 270}, {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 10}, {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 30}, {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 90}, {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 270}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 10}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 30}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 90}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 270}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 30}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 90}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 270}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 10}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 30}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 90}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 270}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 10}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 30}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 90}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 270}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 10}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 90}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 270}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 10}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 30}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 90}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 270}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 10}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 30}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 90}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 270}], 'split0_test_score': array([0.14494359, 0.15752138, 0.20171825, 0.25976755, 0.16444659,\n",
      "       0.1866474 , 0.24792244, 0.31591995, 0.19472279, 0.22360994,\n",
      "       0.29911277, 0.37660886, 0.15240074, 0.18308643, 0.24133847,\n",
      "       0.30080894, 0.17551287, 0.22242563, 0.29669999, 0.36690152,\n",
      "       0.212363  , 0.26845718, 0.35115019, 0.43536071, 0.16551247,\n",
      "       0.21690754, 0.28073989, 0.33992734, 0.20148741, 0.27084186,\n",
      "       0.34374925, 0.42486451, 0.23858043, 0.32308804, 0.40765787,\n",
      "       0.50897467]), 'split1_test_score': array([0.18389178, 0.20766488, 0.23700639, 0.26765067, 0.20361203,\n",
      "       0.2275919 , 0.27251249, 0.3102066 , 0.23044435, 0.25662026,\n",
      "       0.3111621 , 0.35455509, 0.19699579, 0.22804556, 0.25724053,\n",
      "       0.28583932, 0.21193854, 0.25818399, 0.29960576, 0.33480874,\n",
      "       0.24182003, 0.29424411, 0.34135673, 0.38443256, 0.21777392,\n",
      "       0.2448973 , 0.27889387, 0.31237053, 0.24009571, 0.28376572,\n",
      "       0.32148392, 0.37165775, 0.272107  , 0.32649628, 0.37161961,\n",
      "       0.42510759]), 'split2_test_score': array([0.16788112, 0.16805375, 0.18945817, 0.2296133 , 0.19529155,\n",
      "       0.19367763, 0.22738313, 0.27473061, 0.20614732, 0.21672809,\n",
      "       0.27255865, 0.33352604, 0.16996676, 0.17436688, 0.2146826 ,\n",
      "       0.2533844 , 0.1959881 , 0.20889138, 0.26003878, 0.30587673,\n",
      "       0.21672006, 0.25041753, 0.3126094 , 0.37386785, 0.16620899,\n",
      "       0.20325272, 0.24152695, 0.27914479, 0.19479774, 0.24196456,\n",
      "       0.29236523, 0.34024666, 0.22927205, 0.29442076, 0.35921015,\n",
      "       0.40954056]), 'mean_test_score': array([0.165572  , 0.17774651, 0.20939421, 0.2523439 , 0.1877832 ,\n",
      "       0.20263885, 0.24927267, 0.30028585, 0.21043803, 0.23231936,\n",
      "       0.29427788, 0.35489684, 0.17312093, 0.19516619, 0.23775389,\n",
      "       0.28001105, 0.19447968, 0.2298336 , 0.28544827, 0.33586258,\n",
      "       0.22363427, 0.27103959, 0.3350389 , 0.39788734, 0.18316498,\n",
      "       0.22168582, 0.26705368, 0.31048112, 0.21212687, 0.26552409,\n",
      "       0.31919966, 0.37892334, 0.2466531 , 0.31466843, 0.3794961 ,\n",
      "       0.44787476]), 'std_test_score': array([0.01598417, 0.02158791, 0.02015598, 0.0163919 , 0.01684766,\n",
      "       0.01787627, 0.01844863, 0.01822008, 0.01489555, 0.01741139,\n",
      "       0.01612629, 0.01759018, 0.018342  , 0.02352003, 0.01755805,\n",
      "       0.01979479, 0.01490895, 0.02079415, 0.01800623, 0.02492446,\n",
      "       0.01298164, 0.017985  , 0.01635615, 0.02684671, 0.02447372,\n",
      "       0.01733376, 0.01806574, 0.02485036, 0.01996452, 0.01747456,\n",
      "       0.02103957, 0.03492509, 0.01839532, 0.01438463, 0.02054794,\n",
      "       0.04366958]), 'rank_test_score': array([36, 34, 28, 18, 32, 29, 19, 11, 27, 22, 12,  5, 35, 30, 21, 14, 31,\n",
      "       23, 13,  6, 24, 15,  7,  2, 33, 25, 16, 10, 26, 17,  8,  4, 20,  9,\n",
      "        3,  1]), 'split0_train_score': array([0.20678566, 0.21974013, 0.25928402, 0.31574991, 0.2247555 ,\n",
      "       0.24919304, 0.3070701 , 0.37257813, 0.25662026, 0.28779046,\n",
      "       0.3594982 , 0.43867932, 0.21402619, 0.24224458, 0.2969701 ,\n",
      "       0.35642394, 0.23718806, 0.28387311, 0.35294921, 0.42834044,\n",
      "       0.27610665, 0.33048389, 0.41102901, 0.50501237, 0.22653804,\n",
      "       0.27544624, 0.33734202, 0.40392197, 0.26359381, 0.32849059,\n",
      "       0.4038216 , 0.49656542, 0.30361344, 0.3821773 , 0.47427775,\n",
      "       0.59716903]), 'split1_train_score': array([0.19597169, 0.21978666, 0.24858584, 0.2818172 , 0.21722731,\n",
      "       0.24786019, 0.29340652, 0.33121058, 0.24520047, 0.2814358 ,\n",
      "       0.34110572, 0.38588826, 0.21031106, 0.23736586, 0.27118437,\n",
      "       0.29913544, 0.23453853, 0.27671356, 0.32167375, 0.3575016 ,\n",
      "       0.26515635, 0.32206819, 0.37141641, 0.41847025, 0.22951017,\n",
      "       0.25917952, 0.2944142 , 0.32886602, 0.26035582, 0.30662479,\n",
      "       0.34551683, 0.398138  , 0.29808059, 0.35575923, 0.40438381,\n",
      "       0.4604606 ]), 'split2_train_score': array([0.21048469, 0.23889043, 0.27766403, 0.31971962, 0.2406067 ,\n",
      "       0.27389727, 0.3218514 , 0.37098985, 0.26273551, 0.30853075,\n",
      "       0.36861619, 0.43164938, 0.22778387, 0.26179106, 0.30432239,\n",
      "       0.34540241, 0.25658505, 0.30166368, 0.35535777, 0.40312019,\n",
      "       0.28728215, 0.3461391 , 0.4099943 , 0.4732483 , 0.24975009,\n",
      "       0.29264072, 0.33208377, 0.37233778, 0.28620823, 0.33627608,\n",
      "       0.38832316, 0.43813005, 0.3228641 , 0.39080622, 0.45743555,\n",
      "       0.51014304]), 'mean_train_score': array([0.20441401, 0.22613907, 0.26184463, 0.30576224, 0.22752984,\n",
      "       0.2569835 , 0.30744268, 0.35825952, 0.25485208, 0.29258567,\n",
      "       0.3564067 , 0.41873899, 0.2173737 , 0.24713384, 0.29082562,\n",
      "       0.33365393, 0.24277055, 0.28741678, 0.34332691, 0.39632074,\n",
      "       0.27618172, 0.33289706, 0.39747991, 0.46557697, 0.2352661 ,\n",
      "       0.27575549, 0.32128   , 0.36837526, 0.27005262, 0.32379715,\n",
      "       0.37922053, 0.44427782, 0.30818604, 0.37624758, 0.44536571,\n",
      "       0.52259089]), 'std_train_score': array([0.00615767, 0.00901659, 0.01200841, 0.01700909, 0.00974411,\n",
      "       0.01197222, 0.01161556, 0.01913748, 0.00726701, 0.01156949,\n",
      "       0.01144187, 0.02340559, 0.00751572, 0.01055387, 0.01420911,\n",
      "       0.02481952, 0.00982803, 0.01048953, 0.01534263, 0.02931677,\n",
      "       0.00903298, 0.00997396, 0.01843451, 0.03574466, 0.01031335,\n",
      "       0.01366223, 0.01911789, 0.0307693 , 0.01149997, 0.01255178,\n",
      "       0.02465772, 0.04041728, 0.0106219 , 0.01490959, 0.02978312,\n",
      "       0.0565008 ])}\n"
     ]
    }
   ],
   "source": [
    "print(smote_grid.best_estimator_)\n",
    "print(smote_grid.best_score_)\n",
    "print(smote_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the CSV and score it on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining the optimal number of trees for learning rate of 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Classifier model and the Hyperparameter Tuner\n",
    "gb = GradientBoostingClassifier(n_estimators=40, learning_rate=0.2,\n",
    "                                    max_depth=8, subsample=0.8, random_state=0,\n",
    "                                    max_features=int(len(df_train.columns) ** 0.5))\n",
    "parameters = {'n_estimators': [100]}\n",
    "\n",
    "clf = GridSearchCV(gb, parameters, cv=3)\n",
    "print('Determining the optimal number of trees for learning rate of 0.2')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
      "              max_features=13, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=0,\n",
      "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "0.28731184206211263\n",
      "{'mean_fit_time': array([674.17498239]), 'std_fit_time': array([18.49426059]), 'mean_score_time': array([5.57380939]), 'std_score_time': array([0.5182566]), 'param_n_estimators': masked_array(data=[100],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 100}], 'split0_test_score': array([0.04154369]), 'split1_test_score': array([0.29194249]), 'split2_test_score': array([0.52847665]), 'mean_test_score': array([0.28731184]), 'std_test_score': array([0.19881605]), 'rank_test_score': array([1]), 'split0_train_score': array([0.74181466]), 'split1_train_score': array([0.73607168]), 'split2_train_score': array([0.68789572]), 'mean_train_score': array([0.72192735]), 'std_train_score': array([0.02417794])}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time a Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5463a1fe81e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cheater Method — Jupyter Only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gb.fit(X_train, y_train)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2285\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2286\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2287\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2288\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\d\\Anaconda3\\lib\\site-packages\\decorator.py:decorator-gen-62>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1133\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m         \u001b[0mall_runs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m         \u001b[0mworst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[0;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m-> 1194\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cheater Method — Jupyter Only\n",
    "\n",
    "%timeit gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-8f9df12eaa79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                     max_features=int(len(df_train.columns) ** 0.5))\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtestgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Options:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[0;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m-> 1194\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Real Version\n",
    "\n",
    "from time import time\n",
    "\n",
    "initial_t = time()\n",
    "\n",
    "testgb = GradientBoostingClassifier(n_estimators=40, learning_rate=0.2,\n",
    "                                    max_depth=8, subsample=0.8, random_state=0,\n",
    "                                    max_features=int(len(df_train.columns) ** 0.5))\n",
    "\n",
    "testgb.fit(X_train, y_train)\n",
    "\n",
    "# Options:\n",
    "\n",
    "delta_t = time() - initial_t\n",
    "print(f\"It took {delta_t} seconds to train the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still determining the optimal number of trees for learning rate of 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 15, 20, 25, 30, 35, 40, 45]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Classifier model and the Hyperparameter Tuner\n",
    "parameters2 = {'n_estimators': [10, 15, 20, 25, 30, 35, 40, 45]}\n",
    "\n",
    "clf2 = GridSearchCV(gb, parameters2, cv=3)\n",
    "print('Still determining the optimal number of trees for learning rate of 0.2')\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
      "              max_features=13, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "              n_iter_no_change=None, presort='auto', random_state=0,\n",
      "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "0.3708251542508585\n"
     ]
    }
   ],
   "source": [
    "print(clf2.best_estimator_)\n",
    "print(clf2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still determining the optimal number of trees for learning rate of 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [6, 7, 8, 9, 10, 11, 12, 13, 14]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters3 = {'n_estimators': [6, 7, 8, 9, 10, 11, 12, 13, 14]}\n",
    "\n",
    "clf3 = GridSearchCV(gb, parameters3, cv=3)\n",
    "print('Still determining the optimal number of trees for learning rate of 0.2')\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
      "              max_features=13, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=6,\n",
      "              n_iter_no_change=None, presort='auto', random_state=0,\n",
      "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "0.405329560414334\n"
     ]
    }
   ],
   "source": [
    "print(clf3.best_estimator_)\n",
    "print(clf3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still determining the optimal number of trees for learning rate of 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [1, 2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters4 = {'n_estimators': [1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "clf4 = GridSearchCV(gb, parameters4, cv=3)\n",
    "print('Still determining the optimal number of trees for learning rate of 0.2')\n",
    "clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
      "              max_features=13, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=1,\n",
      "              n_iter_no_change=None, presort='auto', random_state=0,\n",
      "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4540526865650665\n"
     ]
    }
   ],
   "source": [
    "print(clf4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still determining the optimal number of trees for learning rate of 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters5 = {'n_estimators': [100]}\n",
    "\n",
    "clf5 = GridSearchCV(gb, parameters5, cv=3)\n",
    "print('Still determining the optimal number of trees for learning rate of 0.2')\n",
    "clf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this overnight to see what happens...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 30, 90], 'learning_rate': [0.05, 0.1, 0.15, 0.2], 'max_depth': [5, 6, 7, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters6 = {'n_estimators': [10, 30, 90],\n",
    "               'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "               'max_depth': [5, 6, 7, 8]}\n",
    "\n",
    "clf6 = GridSearchCV(gb, parameters6, cv=3)\n",
    "print('Running this overnight to see what happens...')\n",
    "clf6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
      "              max_features=13, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=0,\n",
      "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "0.28731184206211263\n"
     ]
    }
   ],
   "source": [
    "print(clf5.best_estimator_)\n",
    "print(clf5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='deviance', max_depth=6,\n",
      "              max_features=13, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "              n_iter_no_change=None, presort='auto', random_state=0,\n",
      "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "0.5434361984717804\n"
     ]
    }
   ],
   "source": [
    "print(clf6.best_estimator_)\n",
    "print(clf6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this overnight to see what happens...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features=13, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 30, 90], 'learning_rate': [0.05, 0.1, 0.15, 0.2], 'max_depth': [6], 'max_features': [13, 56, 85]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters7 = {'n_estimators': [10, 30, 90],\n",
    "               'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "               'max_depth': [6],\n",
    "               'max_features': [int(len(df_train.columns) ** 0.5),\n",
    "                                int(len(df_train.columns) / 3),\n",
    "                                int(len(df_train.columns) / 2)]}\n",
    "\n",
    "clf7 = GridSearchCV(gb, parameters7, cv=3)\n",
    "print('Running this overnight to see what happens...')\n",
    "clf7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='deviance', max_depth=6,\n",
      "              max_features=13, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "              n_iter_no_change=None, presort='auto', random_state=0,\n",
      "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "0.5434361984717804\n"
     ]
    }
   ],
   "source": [
    "print(clf7.best_estimator_)\n",
    "print(clf7.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6104096882246844e-05"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_test = le.fit_transform(id_test)\n",
    "\n",
    "clf7.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6104096882246844e-05"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = smote_grid.predict_proba(X_test)\n",
    "\n",
    "#Taking the 5 classes with highest probabilities\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub.to_csv('sub_smote.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters8 = {'n_estimators': [500, 1000],\n",
    "               'learning_rate': [0.05],\n",
    "               'max_depth': [8],\n",
    "               'max_features': [int(len(df_train.columns) ** 0.5),\n",
    "                                int(len(df_train.columns) / 3),\n",
    "                                int(len(df_train.columns) / 2)]}\n",
    "\n",
    "clf8 = GridSearchCV(gb, parameters8, cv=5)\n",
    "\n",
    "clf8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"poop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clfsmote.predict_proba(X_test)\n",
    "\n",
    "#Taking the 5 classes with highest probabilities\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub.to_csv('subsmote.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [40, 50, 60, 70, 80, 90, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboost SMOTE\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "smote_gb = AdaBoostClassifier()\n",
    "parameters = {'n_estimators': [40, 50, 60, 70, 80, 90, 100]}\n",
    "\n",
    "clfsmote2 = GridSearchCV(smote_gb, parameters, cv=3)\n",
    "\n",
    "clfsmote2.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=None)\n",
      "0.1539127048489277\n",
      "{'mean_fit_time': array([ 277.45087488,  327.68592842,  466.76354225,  602.69548122,\n",
      "        596.75344912,  814.52127306, 8273.60351125]), 'std_fit_time': array([8.66353348e+00, 4.98014633e+00, 6.82749176e+01, 5.62546461e+01,\n",
      "       7.19586211e+01, 2.38505865e+01, 1.03885392e+04]), 'mean_score_time': array([ 8.27778848,  9.93573236, 14.52122498, 17.95810596, 17.94151123,\n",
      "       24.46052329, 26.02718544]), 'std_score_time': array([0.63986763, 0.2332119 , 2.09516008, 1.2687219 , 1.26027955,\n",
      "       0.18229131, 4.93457478]), 'param_n_estimators': masked_array(data=[40, 50, 60, 70, 80, 90, 100],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 40}, {'n_estimators': 50}, {'n_estimators': 60}, {'n_estimators': 70}, {'n_estimators': 80}, {'n_estimators': 90}, {'n_estimators': 100}], 'split0_test_score': array([0.15952066, 0.15620057, 0.16070296, 0.16283271, 0.16336264,\n",
      "       0.16705207, 0.16438637]), 'split1_test_score': array([0.15343619, 0.1553492 , 0.17056696, 0.16239301, 0.16460712,\n",
      "       0.16742143, 0.17410191]), 'split2_test_score': array([0.12023253, 0.12307093, 0.12401037, 0.12315725, 0.12437772,\n",
      "       0.12337003, 0.12324959]), 'mean_test_score': array([0.14439658, 0.14487366, 0.15176017, 0.1494611 , 0.15078259,\n",
      "       0.15261463, 0.1539127 ]), 'std_test_score': array([0.01726607, 0.01542068, 0.02003091, 0.01860038, 0.01867786,\n",
      "       0.02067948, 0.02204177]), 'rank_test_score': array([7, 6, 3, 5, 4, 2, 1]), 'split0_train_score': array([0.18224274, 0.17932505, 0.18171079, 0.18368402, 0.18407846,\n",
      "       0.1803227 , 0.1815241 ]), 'split1_train_score': array([0.18189528, 0.1837631 , 0.19299883, 0.18620301, 0.18603942,\n",
      "       0.19376764, 0.19698338]), 'split2_train_score': array([0.19382485, 0.19871471, 0.19734771, 0.20262298, 0.20199067,\n",
      "       0.20066985, 0.20677514]), 'mean_train_score': array([0.18598762, 0.18726762, 0.19068578, 0.19083667, 0.19070285,\n",
      "       0.19158673, 0.19509421]), 'std_train_score': array([0.00554357, 0.00829461, 0.00658994, 0.00839739, 0.00802174,\n",
      "       0.00844862, 0.01039489])}\n"
     ]
    }
   ],
   "source": [
    "print(clfsmote2.best_estimator_)\n",
    "print(clfsmote2.best_score_)\n",
    "print(clfsmote2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
